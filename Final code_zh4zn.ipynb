{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import torch, torchvision, matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "import dataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "import numpy as np\n",
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "\n",
    "\n",
    "def softmax(a):\n",
    "    max_vel = a.max()\n",
    "    exp_a = (a - max_vel).exp()\n",
    "    return exp_a.div(exp_a.sum())\n",
    "\n",
    "\n",
    "def linear(x, weight, bias):\n",
    "    return torch.matmul(weight, x) + bias\n",
    "\n",
    "\n",
    "def loss(label, predictions):\n",
    "    return -predictions[label].log()\n",
    "\n",
    "\n",
    "\n",
    "def loss_softmax_backward(label, predictions):\n",
    "    grad_inputs = predictions.clone()\n",
    "    grad_inputs[label] = grad_inputs[label] - 1\n",
    "    return grad_inputs\n",
    "\n",
    "\n",
    "\n",
    "def linear_backward(x, weight, bias, gradOutput):\n",
    "    gradBias = bias.clone().zero_()\n",
    "    gradWeight = weight.clone().zero_()\n",
    "    gradWeight = gradOutput * x.t()\n",
    "    gradBias.copy_(gradOutput)\n",
    "\n",
    "    return gradWeight, gradBias"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "This dataset has 1000 training images\nImage 1 is a lighthouse\nImage size is 3x48x48\n",
      "Train-epoch 0. Iteration 00100 / 01000, Avg-Loss: 4.5349, Accuracy: 0.0300\n",
      "Train-epoch 0. Iteration 00200 / 01000, Avg-Loss: 3.9036, Accuracy: 0.0300\n",
      "Train-epoch 0. Iteration 00300 / 01000, Avg-Loss: 3.6511, Accuracy: 0.0267\n",
      "Train-epoch 0. Iteration 00400 / 01000, Avg-Loss: 3.5110, Accuracy: 0.0375\n",
      "Train-epoch 0. Iteration 00500 / 01000, Avg-Loss: 3.4428, Accuracy: 0.0400\n",
      "Train-epoch 0. Iteration 00600 / 01000, Avg-Loss: 3.4047, Accuracy: 0.0367\n",
      "Train-epoch 0. Iteration 00700 / 01000, Avg-Loss: 3.3576, Accuracy: 0.0400\n",
      "Train-epoch 0. Iteration 00800 / 01000, Avg-Loss: 3.3282, Accuracy: 0.0375\n",
      "Train-epoch 0. Iteration 00900 / 01000, Avg-Loss: 3.3390, Accuracy: 0.0389\n",
      "Train-epoch 0. Iteration 01000 / 01000, Avg-Loss: 3.3248, Accuracy: 0.0380\n",
      "Validation-epoch 0. Avg-Loss: 3.0753, Accuracy: 0.0500\n",
      "Train-epoch 1. Iteration 00100 / 01000, Avg-Loss: 3.1286, Accuracy: 0.0200\n",
      "Train-epoch 1. Iteration 00200 / 01000, Avg-Loss: 3.1343, Accuracy: 0.0250\n",
      "Train-epoch 1. Iteration 00300 / 01000, Avg-Loss: 3.1503, Accuracy: 0.0300\n",
      "Train-epoch 1. Iteration 00400 / 01000, Avg-Loss: 3.1519, Accuracy: 0.0300\n",
      "Train-epoch 1. Iteration 00500 / 01000, Avg-Loss: 3.1529, Accuracy: 0.0340\n",
      "Train-epoch 1. Iteration 00600 / 01000, Avg-Loss: 3.1464, Accuracy: 0.0400\n",
      "Train-epoch 1. Iteration 00700 / 01000, Avg-Loss: 3.1425, Accuracy: 0.0386\n",
      "Train-epoch 1. Iteration 00800 / 01000, Avg-Loss: 3.1464, Accuracy: 0.0400\n",
      "Train-epoch 1. Iteration 00900 / 01000, Avg-Loss: 3.1459, Accuracy: 0.0400\n",
      "Train-epoch 1. Iteration 01000 / 01000, Avg-Loss: 3.1433, Accuracy: 0.0400\n",
      "Validation-epoch 1. Avg-Loss: 3.0699, Accuracy: 0.0500\n",
      "Train-epoch 2. Iteration 00100 / 01000, Avg-Loss: 3.1290, Accuracy: 0.0300\n",
      "Train-epoch 2. Iteration 00200 / 01000, Avg-Loss: 3.1335, Accuracy: 0.0300\n",
      "Train-epoch 2. Iteration 00300 / 01000, Avg-Loss: 3.1329, Accuracy: 0.0400\n",
      "Train-epoch 2. Iteration 00400 / 01000, Avg-Loss: 3.1260, Accuracy: 0.0400\n",
      "Train-epoch 2. Iteration 00500 / 01000, Avg-Loss: 3.1232, Accuracy: 0.0420\n",
      "Train-epoch 2. Iteration 00600 / 01000, Avg-Loss: 3.1304, Accuracy: 0.0383\n",
      "Train-epoch 2. Iteration 00700 / 01000, Avg-Loss: 3.1287, Accuracy: 0.0400\n",
      "Train-epoch 2. Iteration 00800 / 01000, Avg-Loss: 3.1258, Accuracy: 0.0437\n",
      "Train-epoch 2. Iteration 00900 / 01000, Avg-Loss: 3.1235, Accuracy: 0.0433\n",
      "Train-epoch 2. Iteration 01000 / 01000, Avg-Loss: 3.1208, Accuracy: 0.0440\n",
      "Validation-epoch 2. Avg-Loss: 3.1220, Accuracy: 0.0500\n",
      "Train-epoch 3. Iteration 00100 / 01000, Avg-Loss: 3.1092, Accuracy: 0.0400\n",
      "Train-epoch 3. Iteration 00200 / 01000, Avg-Loss: 3.1097, Accuracy: 0.0500\n",
      "Train-epoch 3. Iteration 00300 / 01000, Avg-Loss: 3.1184, Accuracy: 0.0467\n",
      "Train-epoch 3. Iteration 00400 / 01000, Avg-Loss: 3.1195, Accuracy: 0.0375\n",
      "Train-epoch 3. Iteration 00500 / 01000, Avg-Loss: 3.1135, Accuracy: 0.0440\n",
      "Train-epoch 3. Iteration 00600 / 01000, Avg-Loss: 3.1155, Accuracy: 0.0433\n",
      "Train-epoch 3. Iteration 00700 / 01000, Avg-Loss: 3.1109, Accuracy: 0.0457\n",
      "Train-epoch 3. Iteration 00800 / 01000, Avg-Loss: 3.1142, Accuracy: 0.0462\n",
      "Train-epoch 3. Iteration 00900 / 01000, Avg-Loss: 3.1157, Accuracy: 0.0456\n",
      "Train-epoch 3. Iteration 01000 / 01000, Avg-Loss: 3.1115, Accuracy: 0.0450\n",
      "Validation-epoch 3. Avg-Loss: 3.1243, Accuracy: 0.0500\n",
      "Train-epoch 4. Iteration 00100 / 01000, Avg-Loss: 3.1453, Accuracy: 0.0300\n",
      "Train-epoch 4. Iteration 00200 / 01000, Avg-Loss: 3.1426, Accuracy: 0.0500\n",
      "Train-epoch 4. Iteration 00300 / 01000, Avg-Loss: 3.1154, Accuracy: 0.0533\n",
      "Train-epoch 4. Iteration 00400 / 01000, Avg-Loss: 3.1102, Accuracy: 0.0475\n",
      "Train-epoch 4. Iteration 00500 / 01000, Avg-Loss: 3.1217, Accuracy: 0.0480\n",
      "Train-epoch 4. Iteration 00600 / 01000, Avg-Loss: 3.1221, Accuracy: 0.0450\n",
      "Train-epoch 4. Iteration 00700 / 01000, Avg-Loss: 3.1198, Accuracy: 0.0529\n",
      "Train-epoch 4. Iteration 00800 / 01000, Avg-Loss: 3.1192, Accuracy: 0.0500\n",
      "Train-epoch 4. Iteration 00900 / 01000, Avg-Loss: 3.1207, Accuracy: 0.0467\n",
      "Train-epoch 4. Iteration 01000 / 01000, Avg-Loss: 3.1230, Accuracy: 0.0480\n",
      "Validation-epoch 4. Avg-Loss: 3.0827, Accuracy: 0.0500\ny_hat[airport_terminal] = 0.06\ny_hat[arch] = 0.09\ny_hat[bathroom] = 0.05\ny_hat[butte] = 0.05\ny_hat[castle] = 0.02\ny_hat[classroom] = 0.03\ny_hat[dentists_office] = 0.03\ny_hat[hot_spring] = 0.06\ny_hat[jacuzzi] = 0.03\ny_hat[laundromat] = 0.07\ny_hat[lecture_room] = 0.04\ny_hat[lighthouse] = 0.04\ny_hat[mountain] = 0.04\ny_hat[sauna] = 0.03\ny_hat[server_room] = 0.06\ny_hat[shower] = 0.03\ny_hat[skyscraper] = 0.09\ny_hat[tower] = 0.07\ny_hat[tree_house] = 0.04\ny_hat[volcano] = 0.05\nTrain-epoch 0. Iteration 00100, Avg_loss: 3.0730, Accuracy: 0.0400\nTrain-epoch 0. Iteration 00200, Avg_loss: 3.0518, Accuracy: 0.0500\nTrain-epoch 0. Iteration 00300, Avg_loss: 3.0464, Accuracy: 0.0533\n",
      "Train-epoch 0. Iteration 00400, Avg_loss: 3.0467, Accuracy: 0.0475\nTrain-epoch 0. Iteration 00500, Avg_loss: 3.0368, Accuracy: 0.0560\nTrain-epoch 0. Iteration 00600, Avg_loss: 3.0230, Accuracy: 0.0600\nTrain-epoch 0. Iteration 00700, Avg_loss: 3.0184, Accuracy: 0.0543\n",
      "Train-epoch 0. Iteration 00800, Avg_loss: 3.0081, Accuracy: 0.0625\nTrain-epoch 0. Iteration 00900, Avg_loss: 3.0042, Accuracy: 0.0611\n",
      "Train-epoch 0. Iteration 01000, Avg_loss: 2.9972, Accuracy: 0.0670\n",
      "Validation epoch: 0, Avg_loss: 2.9042, Accuracy: 0.1220\nTrain-epoch 1. Iteration 00100, Avg_loss: 2.9142, Accuracy: 0.0800\nTrain-epoch 1. Iteration 00200, Avg_loss: 2.9217, Accuracy: 0.0800\nTrain-epoch 1. Iteration 00300, Avg_loss: 2.9176, Accuracy: 0.0867\n",
      "Train-epoch 1. Iteration 00400, Avg_loss: 2.9089, Accuracy: 0.0900\nTrain-epoch 1. Iteration 00500, Avg_loss: 2.9004, Accuracy: 0.1020\nTrain-epoch 1. Iteration 00600, Avg_loss: 2.8852, Accuracy: 0.1100\nTrain-epoch 1. Iteration 00700, Avg_loss: 2.8846, Accuracy: 0.1071\n",
      "Train-epoch 1. Iteration 00800, Avg_loss: 2.8775, Accuracy: 0.1138\nTrain-epoch 1. Iteration 00900, Avg_loss: 2.8747, Accuracy: 0.1144\n",
      "Train-epoch 1. Iteration 01000, Avg_loss: 2.8697, Accuracy: 0.1180\n",
      "Validation epoch: 1, Avg_loss: 2.8189, Accuracy: 0.1550\nTrain-epoch 2. Iteration 00100, Avg_loss: 2.8157, Accuracy: 0.1000\nTrain-epoch 2. Iteration 00200, Avg_loss: 2.8329, Accuracy: 0.1000\n",
      "Train-epoch 2. Iteration 00300, Avg_loss: 2.8275, Accuracy: 0.0933\nTrain-epoch 2. Iteration 00400, Avg_loss: 2.8113, Accuracy: 0.1075\nTrain-epoch 2. Iteration 00500, Avg_loss: 2.8029, Accuracy: 0.1180\n",
      "Train-epoch 2. Iteration 00600, Avg_loss: 2.7863, Accuracy: 0.1317\nTrain-epoch 2. Iteration 00700, Avg_loss: 2.7877, Accuracy: 0.1329\n",
      "Train-epoch 2. Iteration 00800, Avg_loss: 2.7824, Accuracy: 0.1412\nTrain-epoch 2. Iteration 00900, Avg_loss: 2.7800, Accuracy: 0.1411\nTrain-epoch 2. Iteration 01000, Avg_loss: 2.7760, Accuracy: 0.1460\n",
      "Validation epoch: 2, Avg_loss: 2.7568, Accuracy: 0.1730\nTrain-epoch 3. Iteration 00100, Avg_loss: 2.7399, Accuracy: 0.1300\nTrain-epoch 3. Iteration 00200, Avg_loss: 2.7641, Accuracy: 0.1200\nTrain-epoch 3. Iteration 00300, Avg_loss: 2.7580, Accuracy: 0.1200\n",
      "Train-epoch 3. Iteration 00400, Avg_loss: 2.7368, Accuracy: 0.1350\nTrain-epoch 3. Iteration 00500, Avg_loss: 2.7283, Accuracy: 0.1400\nTrain-epoch 3. Iteration 00600, Avg_loss: 2.7107, Accuracy: 0.1633\n",
      "Train-epoch 3. Iteration 00700, Avg_loss: 2.7132, Accuracy: 0.1614\nTrain-epoch 3. Iteration 00800, Avg_loss: 2.7089, Accuracy: 0.1688\n",
      "Train-epoch 3. Iteration 00900, Avg_loss: 2.7068, Accuracy: 0.1700\nTrain-epoch 3. Iteration 01000, Avg_loss: 2.7033, Accuracy: 0.1720\n",
      "Validation epoch: 3, Avg_loss: 2.7103, Accuracy: 0.1720\nTrain-epoch 4. Iteration 00100, Avg_loss: 2.6793, Accuracy: 0.1400\nTrain-epoch 4. Iteration 00200, Avg_loss: 2.7083, Accuracy: 0.1300\nTrain-epoch 4. Iteration 00300, Avg_loss: 2.7021, Accuracy: 0.1300\n",
      "Train-epoch 4. Iteration 00400, Avg_loss: 2.6776, Accuracy: 0.1450\nTrain-epoch 4. Iteration 00500, Avg_loss: 2.6690, Accuracy: 0.1520\nTrain-epoch 4. Iteration 00600, Avg_loss: 2.6506, Accuracy: 0.1750\nTrain-epoch 4. Iteration 00700, Avg_loss: 2.6537, Accuracy: 0.1757\n",
      "Train-epoch 4. Iteration 00800, Avg_loss: 2.6499, Accuracy: 0.1825\nTrain-epoch 4. Iteration 00900, Avg_loss: 2.6479, Accuracy: 0.1833\n",
      "Train-epoch 4. Iteration 01000, Avg_loss: 2.6447, Accuracy: 0.1850\n",
      "Validation epoch: 4, Avg_loss: 2.6742, Accuracy: 0.1830\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "class TwoLayerNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TwoLayerNN, self).__init__()\n",
    "\n",
    "        self.linear1 = nn.Linear(3 * 48 * 48, 512)\n",
    "        self.linear2 = nn.Linear(512, 20)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 3 * 48 * 48)\n",
    "        z = F.relu(self.linear1(x))\n",
    "        return self.linear2(z)\n",
    "\n",
    "\n",
    "alex_model = models.AlexNet()\n",
    "alex_model.classifier[6] = nn.Linear(4096, 20)\n",
    "\n",
    "\n",
    "transform = transforms.Compose([ transforms.ToTensor()])\n",
    "image_index = 1\n",
    "\n",
    "# 20 scene categories from the SUN397 dataset.\n",
    "classes = ['airport_terminal', 'arch', 'bathroom', 'butte', 'castle',\n",
    "           'classroom', 'dentists_office', 'hot_spring', 'jacuzzi',\n",
    "           'laundromat', 'lecture_room', 'lighthouse', 'mountain',\n",
    "           'sauna', 'server_room', 'shower', 'skyscraper', 'tower',\n",
    "           'tree_house', 'volcano']\n",
    "\n",
    "\n",
    "train_set = dataset.SUN20(split='train', transform=transform)\n",
    "val_set = dataset.SUN20(split='validation', transform=transform)\n",
    "print('This dataset has {0} training images'.format(len(train_set)))\n",
    "img, label = train_set[image_index]  # Returns image and label.\n",
    "print('Image {0} is a {1}'.format(image_index, classes[label]))\n",
    "print('Image size is {0}x{1}x{2}'.format(img.shape[0], img.shape[1], img.shape[2]))\n",
    "# All images have 3 channel x 48 rows x 48 columns.\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(img.transpose(0, 2).transpose(0, 1))\n",
    "plt.grid(False)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "batchSize = 1\n",
    "\n",
    "# Create the model.\n",
    "model = TwoLayerNN()\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "learningRate = 5e-2\n",
    "\n",
    "# Optimizer.\n",
    "optimizer = optim.SGD(model.parameters(), lr=learningRate, momentum=0.9, weight_decay=1e-4)\n",
    "\n",
    "#optimizer = optim.Adam(cnn_model.parameters(), lr = 3e-3)\n",
    "\n",
    "\n",
    "def train_model(model, loss_fn, batchSize, trainset, valset, optimizer, num_epochs):\n",
    "    # Shuffling is needed in case dataset is not shuffled by default.\n",
    "    train_loader = torch.utils.data.DataLoader(dataset=trainset,\n",
    "                                               batch_size=batchSize,\n",
    "                                               shuffle=True)\n",
    "    # We don't need to bach the validation set but let's do it anyway.\n",
    "    val_loader = torch.utils.data.DataLoader(dataset=valset,\n",
    "                                             batch_size=batchSize,\n",
    "                                             shuffle=False)  # No need.\n",
    "\n",
    "    # Define number of epochs.\n",
    "    N = num_epochs\n",
    "\n",
    "    # log accuracies and losses.\n",
    "    train_accuracies = []\n",
    "    val_accuracies = []\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    for epoch in range(0, N):\n",
    "        correct = 0.0\n",
    "        cum_loss = 0.0\n",
    "\n",
    "        # Make a pass over the training data.\n",
    "        model.train()\n",
    "        for (i, (inputs, labels)) in enumerate(train_loader):\n",
    "            #inputs = inputs.unsqueeze_(2)\n",
    "            # Forward pass. (Prediction stage)\n",
    "            scores = model(inputs)\n",
    "            loss = loss_fn(scores, labels)\n",
    "\n",
    "            # Count how many correct in this batch.\n",
    "            max_scores, max_labels = scores.max(1)\n",
    "            correct += (max_labels == labels).sum().item()\n",
    "            cum_loss += loss.item()\n",
    "\n",
    "            # Zero the gradients in the network.\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Backward pass. (Gradient computation stage)\n",
    "            loss.backward()\n",
    "\n",
    "            # Parameter updates (SGD step) -- if done with torch.optim!\n",
    "            optimizer.step()\n",
    "\n",
    "            # Parameter updates (SGD step) -- if done manually!\n",
    "            # for param in model.parameters():\n",
    "            #   param.data.add_(-learningRate, param.grad)\n",
    "\n",
    "            # Logging the current results on training.\n",
    "            if (i + 1) % 100 == 0:\n",
    "                print('Train-epoch %d. Iteration %05d / %05d, Avg-Loss: %.4f, Accuracy: %.4f' %\n",
    "                      (epoch, i + 1, len(train_loader), cum_loss / (i + 1), correct / ((i + 1) * batchSize)))\n",
    "\n",
    "        train_accuracies.append(correct / len(trainset))\n",
    "        train_losses.append(cum_loss / (i + 1))\n",
    "\n",
    "        # Make a pass over the validation data.\n",
    "        correct = 0.0\n",
    "        cum_loss = 0.0\n",
    "        model.eval()\n",
    "        for (i, (inputs, labels)) in enumerate(val_loader):\n",
    "\n",
    "\n",
    "            # Forward pass. (Prediction stage)\n",
    "            #inputs = inputs.unsqueeze_(2)\n",
    "            scores = model(inputs)\n",
    "            cum_loss += loss_fn(scores, labels).item()\n",
    "\n",
    "            # Count how many correct in this batch.\n",
    "            max_scores, max_labels = scores.max(1)\n",
    "            correct += (max_labels == labels).sum().item()\n",
    "\n",
    "        val_accuracies.append(correct / len(valset))\n",
    "        val_losses.append(cum_loss / (i + 1))\n",
    "\n",
    "        # Logging the current results on validation.\n",
    "        print('Validation-epoch %d. Avg-Loss: %.4f, Accuracy: %.4f' %\n",
    "              (epoch, cum_loss / (i + 1), correct / len(valset)))\n",
    "    return train_losses, val_losses, train_accuracies, val_accuracies\n",
    "\n",
    "\n",
    "train_losses, val_losses, train_accuracies,val_accuracies = train_model(model, loss_fn, batchSize, train_set, val_set, optimizer, 5)\n",
    "\n",
    "\n",
    "\n",
    "weight = torch.zeros(20, 3* 48 * 48).normal_(0, 0.01)\n",
    "bias = torch.zeros(20, 1).normal_(0, 0.01)\n",
    "\n",
    "x = img.view(3*48*48, 1)\n",
    "a = linear(x, weight, bias)\n",
    "predictions = softmax(a)\n",
    "\n",
    "for i, pred in enumerate(predictions.squeeze().tolist()):\n",
    "    print(\"y_hat[%s] = %.2f\" % (classes[i], pred))\n",
    "\n",
    "learningRate = 1e-4\n",
    "N = 5\n",
    "\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "train_loss = []\n",
    "val_loss = []\n",
    "\n",
    "\n",
    "for epoch in range(0, N):\n",
    "    correct = 0.0\n",
    "    cum_loss = 0.0\n",
    "    for (i, (img, label)) in enumerate(train_set):\n",
    "        x = img.view(3*48*48, 1)\n",
    "        predictions = softmax(linear(x, weight, bias))\n",
    "        cum_loss += loss(label, predictions).item()\n",
    "        max_score, max_label = predictions.max(0)\n",
    "        if max_label[0] == label: correct += 1\n",
    "\n",
    "        gradOutput = loss_softmax_backward(label, predictions)\n",
    "        gradWeight, gradBias = linear_backward(x, weight, bias, gradOutput)\n",
    "        weight.add_(-learningRate, gradWeight)\n",
    "        bias.add_(-learningRate, gradBias)\n",
    "\n",
    "        if(i + 1) % 100 == 0:\n",
    "            print(\"Train-epoch %d. Iteration %05d, Avg_loss: %.4f, Accuracy: %.4f\" %\n",
    "                  (epoch, i + 1, cum_loss/(i + 1), correct / (i + 1)))\n",
    "\n",
    "    train_accuracies.append(correct / len(train_set))\n",
    "    train_loss.append(cum_loss / len(train_set))\n",
    "\n",
    "\n",
    "    correct = 0\n",
    "    cum_loss = 0\n",
    "    for(i, (img, label)) in enumerate(val_set):\n",
    "        x = img.view(3*48*48, 1)\n",
    "        predictions = softmax(linear(x, weight, bias))\n",
    "        cum_loss += loss(label, predictions).item()\n",
    "        max_score, max_label = predictions.max(0)\n",
    "        if max_label[0] == label: correct += 1\n",
    "\n",
    "    val_accuracies.append(correct / len(val_set))\n",
    "    val_loss.append(cum_loss / len(val_set))\n",
    "\n",
    "    print(\"Validation epoch: %d, Avg_loss: %.4f, Accuracy: %.4f\" %\n",
    "          (epoch, cum_loss/len(val_set), correct/len(val_set)))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "10\n10 airport_terminal\nUser: \n10 airport_terminal\n11 airport_terminal\n9 airport_terminal\n15 airport_terminal\n_____ \nUser1: \n10 airport_terminal\n11 airport_terminal\n9 airport_terminal\n15 airport_terminal\n_____ \nUser2: \n9 airport_terminal\n15 airport_terminal\n6 airport_terminal\n15 airport_terminal\n_____ \nUser3: \n10 airport_terminal\n11 airport_terminal\n9 airport_terminal\n15 airport_terminal\n10.0 10.0 10.0\nsimilarity 1:  10.0\nsimilarity 2:  10.0\nsimilarity 3:  10.0\nDecision beliefs: User 1\n",
      "Matching score: 0.0800\n",
      "Matching score: 0.2400\n",
      "Matching score: 0.2800\nNew Decision: User:  1\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "import numpy as np\n",
    "img, label = val_set[1]\n",
    "print(label)\n",
    "scores = model(img)\n",
    "max_scores, max_labels = scores.max(1)\n",
    "max_scores = max_scores.data.numpy()\n",
    "\n",
    "idx = np.argmax(max_scores)\n",
    "print(label, classes[idx])\n",
    "\n",
    "m = [1, 2, 3, 4]\n",
    "m1 = [1, 2, 3, 4]\n",
    "m2 = [3, 4, 6, 5]\n",
    "m3 = [5, 6, 7, 8]\n",
    "\n",
    "m_matrix = np.array([])\n",
    "print(\"User: \")\n",
    "for i in range(0, 4):\n",
    "    img, label = val_set[m[i]]\n",
    "    predictions = model(img)\n",
    "    max_score, max_label = predictions.max(1)\n",
    "\n",
    "    idx = np.argmax(max_scores)\n",
    "    m_matrix = np.append(m_matrix, max_label.item())\n",
    "    print(label, classes[idx])\n",
    "m_matrix.shape = (2, 2)\n",
    "\n",
    "\n",
    "print(\"_____ \")\n",
    "m1_matrix = np.array([])\n",
    "print(\"User1: \")\n",
    "for i in range(0, 4):\n",
    "    img, label = val_set[m1[i]]\n",
    "    predictions = model(img)\n",
    "    max_score, max_label = predictions.max(1)\n",
    "\n",
    "    idx = np.argmax(max_scores)\n",
    "    m1_matrix = np.append(m1_matrix, max_label.item())\n",
    "    print(label, classes[idx])\n",
    "m1_matrix.shape = (2, 2)\n",
    "\n",
    "print(\"_____ \")\n",
    "m2_matrix = np.array([])\n",
    "print(\"User2: \")\n",
    "for i in range(0, 4):\n",
    "    img, label = val_set[m2[i]]\n",
    "    predictions = model(img)\n",
    "    max_score, max_label = predictions.max(1)\n",
    "\n",
    "    idx = np.argmax(max_scores)\n",
    "    m2_matrix = np.append(m2_matrix, max_label.item())\n",
    "    print(label, classes[idx])\n",
    "\n",
    "m2_matrix.shape = (2, 2)\n",
    "\n",
    "\n",
    "print(\"_____ \")\n",
    "m3_matrix = np.array([])\n",
    "print(\"User3: \")\n",
    "for i in range(0, 4):\n",
    "    img, label = val_set[m[i]]\n",
    "    predictions = model(img)\n",
    "    max_score, max_label = predictions.max(1)\n",
    "\n",
    "    idx = np.argmax(max_scores)\n",
    "    m3_matrix = np.append(m3_matrix, max_label.item())\n",
    "    print(label, classes[idx])\n",
    "\n",
    "m3_matrix.shape = (2, 2)\n",
    "\n",
    "dis1m = pairwise_distances(m_matrix, m1_matrix)\n",
    "dis2m = pairwise_distances(m_matrix, m2_matrix)\n",
    "dis3m = pairwise_distances(m_matrix, m3_matrix)\n",
    "\n",
    "dis_mean1 = np.mean(dis1m)\n",
    "dis_mean2 = np.mean(dis2m)\n",
    "dis_mean3 = np.mean(dis3m)\n",
    "\n",
    "s1 = 10-dis_mean1\n",
    "s2 = 10-dis_mean2\n",
    "s3 = 10-dis_mean3\n",
    "print(s1, s2, s3)\n",
    "\n",
    "print(\"similarity 1: \", s1)\n",
    "\n",
    "print(\"similarity 2: \", s2)\n",
    "\n",
    "print(\"similarity 3: \", s3)\n",
    "\n",
    "prior_decision = []\n",
    "prior_decision.append(s1)\n",
    "prior_decision.append(s2)\n",
    "prior_decision.append(s3)\n",
    "\n",
    "prior_result = np.array(prior_decision)\n",
    "print(\"Decision beliefs: User\", np.argmax(prior_result)+1)\n",
    "\n",
    "action_set = [10, 10, 10]\n",
    "\n",
    "action_set = [2, 4, 5]\n",
    "w1 = 0.2\n",
    "w2 = 0.8\n",
    "w3 = 2\n",
    "\n",
    "matching_rate = 0\n",
    "\n",
    "matching_rate = 0\n",
    "final_result = np.array([])\n",
    "result1 = int(input(\"input the user you want to choose: 1 = user1, 2 = user2, 3 = user 3, 4 = give up\"))\n",
    "matching_rate1 = int(result1)/2\n",
    "if int(result1) == 0:\n",
    "    matching_rate = 0\n",
    "\n",
    "matching_formula1 = (w1 * action_set[0] + w2 * matching_rate) * w3 * 0.1\n",
    "print(\"Matching score: %.4f\"% matching_formula1)\n",
    "\n",
    "final_result = np.append(final_result, matching_formula1)\n",
    "\n",
    "\n",
    "result2 = int(input(\"input the user you want to choose: 1 = user1, 2 = user2, 3 =  give up\"))\n",
    "matching_rate2 = int(result2)/2\n",
    "if int(result2) == 3:\n",
    "    matching_rate2 = 0\n",
    "matching_formula2 = (w1 * action_set[1] + w2 * matching_rate2)* w3 * 0.1\n",
    "print(\"Matching score: %.4f\"% matching_formula2)\n",
    "final_result = np.append(final_result, matching_formula2)\n",
    "\n",
    "result3 = int(input(\"input the user you want to choose: 1 = user1, 2 = give up\"))\n",
    "matching_rate3 = int(result2)/2\n",
    "if int(result3) == 2:\n",
    "    matching_rate3 = 0\n",
    "\n",
    "matching_formula3 = (w1 * action_set[2] + w2 * matching_rate3)*w3 * 0.1\n",
    "print(\"Matching score: %.4f\"% matching_formula3)\n",
    "final_result = np.append(final_result, matching_formula3)\n",
    "print(\"New Decision: User: \", 3 - np.argmax(final_result))\n",
    "new_decision = np.array([])\n",
    "new_decision = np.append(new_decision, 3 - np.argmax(final_result))#save user\n",
    "idx = np.argmax(final_result)\n",
    "new_decision = np.append(new_decision, final_result[idx])#save score\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "User: \nlecture_room\nlighthouse\nlaundromat\nshower\n_____ \nUser1: \nlecture_room\nlighthouse\nlaundromat\nshower\n_____ \nUser2: \nlaundromat\nshower\ndentists_office\nshower\n_____ \nUser3: \nshower\ndentists_office\nsauna\nmountain\n_____ \n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# model 2\n",
    "u = [1, 2, 3, 4]\n",
    "u1 = [1, 2, 3, 4]\n",
    "u2 = [3, 4, 6, 5]\n",
    "u3 = [5, 6, 7, 8]\n",
    "\n",
    "u_matrix = np.array([])\n",
    "print(\"User: \")\n",
    "for i in range(0, 4):\n",
    "    img, label = val_set[u[i]]\n",
    "    #img = F.to_tensor(img)\n",
    "    x = img.view(3 * 48 * 48, 1)\n",
    "    a = linear(x, weight, bias)\n",
    "    predictions = softmax(a)\n",
    "    max_score, max_label = predictions.max(0)\n",
    "    u_matrix = np.append(u_matrix, max_label.item())\n",
    "    print(classes[label])\n",
    "\n",
    "u_matrix.shape = (2, 2)\n",
    "\n",
    "print(\"_____ \")\n",
    "print(\"User1: \")\n",
    "\n",
    "u1_matrix = np.array([])\n",
    "for i in range(0, 4):\n",
    "    img, label = val_set[u1[i]]\n",
    "    #img = F.to_tensor(img)\n",
    "    x = img.view(3 * 48 * 48, 1)\n",
    "    a = linear(x, weight, bias)\n",
    "    predictions = softmax(a)\n",
    "    max_score, max_label = predictions.max(0)\n",
    "    u1_matrix = np.append(u1_matrix, max_label.item())\n",
    "    print(classes[label])\n",
    "\n",
    "u1_matrix.shape = (2, 2)\n",
    "print(\"_____ \")\n",
    "print(\"User2: \")\n",
    "\n",
    "u2_matrix = np.array([])\n",
    "for i in range(0, 4):\n",
    "    img, label = val_set[u2[i]]\n",
    "    #img = F.to_tensor(img)\n",
    "    x = img.view(3 * 48 * 48, 1)\n",
    "    a = linear(x, weight, bias)\n",
    "    predictions = softmax(a)\n",
    "    max_score, max_label = predictions.max(0)\n",
    "    u2_matrix = np.append(u2_matrix, max_label.item())\n",
    "    print(classes[label])\n",
    "\n",
    "u2_matrix.shape = (2, 2)\n",
    "print(\"_____ \")\n",
    "\n",
    "print(\"User3: \")\n",
    "u3_matrix = np.array([])\n",
    "for i in range(0, 4):\n",
    "    img, label = val_set[u3[i]]\n",
    "    #img = F.to_tensor(img)\n",
    "    x = img.view(3 * 48 * 48, 1)\n",
    "    a = linear(x, weight, bias)\n",
    "    predictions = softmax(a)\n",
    "    max_score, max_label = predictions.max(0)\n",
    "    u3_matrix = np.append(u3_matrix, max_label.item())\n",
    "    print(classes[label])\n",
    "\n",
    "print(\"_____ \")\n",
    "u3_matrix.shape = (2, 2)\n",
    "\n",
    "dis1 = pairwise_distances(u_matrix, u1_matrix)\n",
    "dis2 = pairwise_distances(u_matrix, u2_matrix)\n",
    "dis3 = pairwise_distances(u_matrix, u3_matrix)\n",
    "\n",
    "dis_mean1 = np.mean(dis1)\n",
    "dis_mean2 = np.mean(dis2)\n",
    "dis_mean3 = np.mean(dis3)\n",
    "\n",
    "s1 = 10-dis_mean1\n",
    "s2 = 10-dis_mean2\n",
    "s3 = 10-dis_mean3\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "similarity 1:  6.0\nsimilarity 2:  3.3654721887248975\nsimilarity 3:  -1.1837867478493056\nDecision beliefs: User 1\n",
      "Matching Score: 0.1600\n",
      "Matching score: 0.6400\n",
      "Matching score: 0.4000\nNew Decision: User:  2\nCompared with previous recommendation, Final Decision: User:  2\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "## Match based on similarity\n",
    "print(\"similarity 1: \", s1)\n",
    "\n",
    "print(\"similarity 2: \", s2)\n",
    "\n",
    "print(\"similarity 3: \", s3)\n",
    "\n",
    "prior_decision = []\n",
    "prior_decision.append(s1)\n",
    "prior_decision.append(s2)\n",
    "prior_decision.append(s3)\n",
    "\n",
    "prior_result = np.array(prior_decision)\n",
    "print(\"Decision beliefs: User\", np.argmax(prior_result)+1)\n",
    "\n",
    "\n",
    "action_set = [2, 4, 5]\n",
    "w1 = 0.2\n",
    "w2 = 0.8\n",
    "w3 = 2\n",
    "\n",
    "matching_rate = 0\n",
    "final_result = np.array([])\n",
    "result1 = input(\"input the user you want to choose: 1 = user1, 2 = user2, 3 = user 3, 4 = give up\")\n",
    "matching_rate1 = int(result1)/2\n",
    "if int(result1) == 0:\n",
    "    matching_rate = 0\n",
    "matching_formula1 = (w1 * action_set[0] + w2 * matching_rate) * w3 * 0.2\n",
    "print(\"Matching Score: %.4f\"% (matching_formula1))\n",
    "\n",
    "final_result = np.append(final_result, matching_formula1)\n",
    "\n",
    "\n",
    "result2 = input(\"input the user you want to choose: 1 = user1, 2 = user2, 3 =  give up\")\n",
    "matching_rate2 = int(result2)/2\n",
    "if int(result2) == 3:\n",
    "    matching_rate2 = 0\n",
    "matching_formula2 = (w1 * action_set[1] + w2 * matching_rate2 )* w3 * 0.2\n",
    "print(\"Matching score: %.4f\"% (matching_formula2))\n",
    "final_result = np.append(final_result, matching_formula2)\n",
    "\n",
    "result3 = input(\"input the user you want to choose: 1 = user1, 2 = give up\")\n",
    "matching_rate3 = int(result2)/2\n",
    "if int(result3) == 2:\n",
    "    matching_rate3 = 0\n",
    "\n",
    "matching_formula3 = (w1 * action_set[2] + w2 * matching_rate3) * w3 * 0.2\n",
    "print(\"Matching score: %.4f\"% (matching_formula3))\n",
    "final_result = np.append(final_result, matching_formula3)\n",
    "print(\"New Decision: User: \", 3 - np.argmax(final_result))\n",
    "\n",
    "#print(new_decision)\n",
    "if(new_decision[1] < np.argmax(final_result)):\n",
    "    print(\"Compared with previous recommendation, Final Decision: User: \", 3 - np.argmax(final_result))\n",
    "\n",
    "else:\n",
    "    print(\"Compared with previous recommendation, Final Decision: User: \", new_decision[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-1b855516",
   "language": "python",
   "display_name": "PyCharm (Assignments)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}